def pklc_fovcatalog_objectinfo(
        pklcdir,
        fovcatalog,
        fovcatalog_columns=[0,1,2,
                            6,7,
                            8,9,
                            10,11,
                            13,14,15,16,
                            17,18,19,
                            20,21],
        fovcatalog_colnames=['objectid','ra','decl',
                             'jmag','jmag_err',
                             'hmag','hmag_err',
                             'kmag','kmag_err',
                             'bmag','vmag','rmag','imag',
                             'sdssu','sdssg','sdssr',
                             'sdssi','sdssz'],
        fovcatalog_colformats=('U20,f8,f8,'
                               'f8,f8,'
                               'f8,f8,'
                               'f8,f8,'
                               'f8,f8,f8,f8,'
                               'f8,f8,f8,'
                               'f8,f8')
):
    '''Adds catalog info to objectinfo key of all pklcs in lcdir.

    If fovcatalog, fovcatalog_columns, fovcatalog_colnames are provided, uses
    them to find all the additional information listed in the fovcatalog_colname
    keys, and writes this info to the objectinfo key of each lcdict. This makes
    it easier for astrobase tools to work on these light curve.

    The default set up for fovcatalog is to use a text file generated by the
    HATPI pipeline before auto-calibrating a field. The format is specified as
    above in _columns,  _colnames, and _colformats.

    '''

    if fovcatalog.endswith('.gz'):
        catfd = gzip.open(fovcatalog)
    else:
        catfd = open(fovcatalog)

    # read the catalog using the colformats, etc.
    fovcat = np.genfromtxt(catfd,
                           usecols=fovcatalog_columns,
                           names=fovcatalog_colnames,
                           dtype=fovcatalog_colformats)
    catfd.close()

    pklclist = sorted(glob.glob(os.path.join(pklcdir, '*HAT*-pklc.pkl')))

    updatedpklcs, failedpklcs = [], []

    for pklc in pklclist:

        lcdict = read_hatpi_pklc(pklc)
        objectid = lcdict['objectid']

        catind = np.where(fovcat['objectid'] == objectid)

        # if we found catalog info for this object, put it into objectinfo
        if len(catind) > 0 and catind[0]:

            lcdict['objectinfo'].update(
                {x:y for x,y in zip(
                    fovcatalog_colnames,
                    [np.asscalar(fovcat[z][catind]) for
                     z in fovcatalog_colnames]
                )
                }
            )

            # write the LC back to the pickle (tempfile for atomicity)
            with open(pklc+'-tmp','wb') as outfd:
                pickle.dump(lcdict, outfd, pickle.HIGHEST_PROTOCOL)

            # overwrite previous once we know it exists
            if os.path.exists(pklc+'-tmp'):
                shutil.move(pklc+'-tmp',pklc)

                LOGINFO('updated %s with catalog info for %s at %.3f, %.3f OK' %
                        (pklc, objectid,
                         lcdict['objectinfo']['ra'],
                         lcdict['objectinfo']['decl']))

                updatedpklcs.append(pklc)

        # otherwise, do nothing
        else:
            failedpklcs.append(pklc)

    # end of pklclist processing
    return updatedpklcs, failedpklcs